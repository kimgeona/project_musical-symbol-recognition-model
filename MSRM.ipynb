{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 패키지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chorokmoo/_MyDev/_Anaconda/anaconda3/envs/new/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/Users/chorokmoo/_MyDev/_Anaconda/anaconda3/envs/new/lib/python3.10/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.12.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf             # 텐서플로\n",
    "import tensorflow_addons as tfa     # 텐서플로 애드온\n",
    "import pandas as pd                 # 판다스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU 사용 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용 가능한 모든 GPU 리스트\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "# 사용할 프로세서 선택 : GPU\n",
    "if gpus:\n",
    "    try: tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    except RuntimeError as e: print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터셋 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 주소\n",
    "dataset_dir = os.path.join('.', 'datasets', 'MusicalSymbol-v.1.1.5')\n",
    "\n",
    "# CSV 파일 주소\n",
    "csv_dir = os.path.join(dataset_dir, 'label.csv')\n",
    "\n",
    "# csv 파일 불러오기\n",
    "df = pd.read_csv(csv_dir)\n",
    "\n",
    "# name을 정수값으로 추출\n",
    "df['name_int'] = df['name'].str.extract('(\\d+)').astype(int)\n",
    "\n",
    "# 정수값을 기준으로 정렬 및 인덱스 초기화\n",
    "df = df.sort_values('name_int')\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# 필요 없는 name, name_int 열 제거\n",
    "df = df.drop(columns=['name', 'name_int'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_extract(dataframe, keywords):\n",
    "    # 빈 데이터 프레임 생성\n",
    "    new_df = pd.DataFrame()\n",
    "\n",
    "    # 기존 데이터 프레임 추출 시작\n",
    "    for key in keywords:\n",
    "        # 키워드 추출\n",
    "        name_list = [s for s in dataframe.columns.to_numpy() if key in s]\n",
    "        \n",
    "        # 추출된 키워드 열 끼리 병합\n",
    "        for n in name_list:\n",
    "            # 키워드 열 끼리 or 연산\n",
    "            if key in new_df:   new_df[key.strip()] = new_df[key] | dataframe[n]\n",
    "            else:               new_df[key.strip()] = dataframe[n]\n",
    "    \n",
    "    # 새로 생성된 데이터 프레임 반환\n",
    "    return new_df\n",
    "\n",
    "def column_pick(dataframe, keywords):\n",
    "    # 빈 데이터 프레임 생성\n",
    "    new_df = pd.DataFrame()\n",
    "\n",
    "    # 기존 데이터 프레임 추출 시작\n",
    "    for key in keywords:\n",
    "        # 키워드 추출\n",
    "        name_list = [s for s in dataframe.columns.to_numpy() if key in s]\n",
    "\n",
    "        # 추출된 키워드로 데이터 프레임 새로 만들기\n",
    "        for n in name_list:\n",
    "            new_df[n.strip()] = dataframe[n]\n",
    "    \n",
    "    # 새로 생성된 데이터 프레임 반환\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['note' 'accidental' 'articulation' 'dynamic' 'octave' 'ornament'\n",
      " 'repetition' 'clef' 'key' 'measure' 'rest' 'time']\n"
     ]
    }
   ],
   "source": [
    "# 악상 기호 전체 분류\n",
    "df_all = column_extract(df, keywords=[ \n",
    "    'note', \n",
    "    'accidental', \n",
    "    'articulation', \n",
    "    'dynamic', \n",
    "    'octave', \n",
    "    'ornament', \n",
    "    'repetition', \n",
    "    'clef', \n",
    "    'key', \n",
    "    'measure', \n",
    "    'rest', \n",
    "    'time'\n",
    "])\n",
    "\n",
    "# 악상 기호 세부 분류\n",
    "df_pitch        = column_pick(df, keywords=['staff-']).drop(columns=['staff-half-left', 'staff-half-right'])\n",
    "df_note         = column_pick(df, keywords=['note'])\n",
    "df_accidental   = column_pick(df, keywords=['accidental'])\n",
    "df_dynamic      = column_pick(df, keywords=['dynamic'])\n",
    "df_octave       = column_pick(df, keywords=['octave'])\n",
    "df_ornament     = column_pick(df, keywords=['ornament'])\n",
    "df_repetition   = column_pick(df, keywords=['repetition'])\n",
    "df_clef         = column_pick(df, keywords=['clef'])\n",
    "df_key          = column_pick(df, keywords=['key'])\n",
    "df_measure      = column_pick(df, keywords=['measure'])\n",
    "df_rest         = column_pick(df, keywords=['rest'])\n",
    "df_time         = column_pick(df, keywords=['time'])\n",
    "\n",
    "#\n",
    "print(df_all.columns.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pandas 데이터 프레임을 tensorflow 텐서로 변환\n",
    "df_all          = tf.convert_to_tensor(df_all.values, dtype=tf.int16)\n",
    "df_pitch        = tf.convert_to_tensor(df_pitch.values, dtype=tf.int16)\n",
    "df_note         = tf.convert_to_tensor(df_note.values, dtype=tf.int16)\n",
    "df_accidental   = tf.convert_to_tensor(df_accidental.values, dtype=tf.int16)\n",
    "df_dynamic      = tf.convert_to_tensor(df_dynamic.values, dtype=tf.int16)\n",
    "df_octave       = tf.convert_to_tensor(df_octave.values, dtype=tf.int16)\n",
    "df_ornament     = tf.convert_to_tensor(df_ornament.values, dtype=tf.int16)\n",
    "df_repetition   = tf.convert_to_tensor(df_repetition.values, dtype=tf.int16)\n",
    "df_clef         = tf.convert_to_tensor(df_clef.values, dtype=tf.int16)\n",
    "df_key          = tf.convert_to_tensor(df_key.values, dtype=tf.int16)\n",
    "df_measure      = tf.convert_to_tensor(df_measure.values, dtype=tf.int16)\n",
    "df_rest         = tf.convert_to_tensor(df_rest.values, dtype=tf.int16)\n",
    "df_time         = tf.convert_to_tensor(df_time.values, dtype=tf.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 분류\n",
      "df_all        : (22617, 12) \n",
      "\n",
      "세부 분류\n",
      "df_pitch      : (22617, 11)\n",
      "df_note       : (22617, 14)\n",
      "df_accidental : (22617, 5)\n",
      "df_dynamic    : (22617, 18)\n",
      "df_octave     : (22617, 8)\n",
      "df_ornament   : (22617, 7)\n",
      "df_repetition : (22617, 12)\n",
      "df_clef       : (22617, 9)\n",
      "df_key        : (22617, 14)\n",
      "df_measure    : (22617, 6)\n",
      "df_rest       : (22617, 15)\n",
      "df_time       : (22617, 2)\n"
     ]
    }
   ],
   "source": [
    "# shape 출력\n",
    "print('전체 분류')\n",
    "print('--------------------------------')\n",
    "print('df_all        :', df_all.shape, '\\n')\n",
    "\n",
    "print('세부 분류')\n",
    "print('--------------------------------')\n",
    "print('df_pitch      :', df_pitch.shape)\n",
    "print('df_note       :', df_note.shape)\n",
    "print('df_accidental :', df_accidental.shape)\n",
    "print('df_dynamic    :', df_dynamic.shape)\n",
    "print('df_octave     :', df_octave.shape)\n",
    "print('df_ornament   :', df_ornament.shape)\n",
    "print('df_repetition :', df_repetition.shape)\n",
    "print('df_clef       :', df_clef.shape)\n",
    "print('df_key        :', df_key.shape)\n",
    "print('df_measure    :', df_measure.shape)\n",
    "print('df_rest       :', df_rest.shape)\n",
    "print('df_time       :', df_time.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def make_data(img_path):\n",
    "    # 타겟 생성\n",
    "    image = tf.io.read_file(img_path)               # 파일 로드\n",
    "    image = tf.image.decode_png(image, channels=1)  # png 파일로 변환\n",
    "    image = tf.cast(image, tf.float32)              # uint8 -> float32\n",
    "    image = image / 255.0                           # 0~1 로 정규화\n",
    "    image = 1.0 - image                             # 흑백 이미지 반전\n",
    "\n",
    "    # 파일 이름에서 인덱스 얻기\n",
    "    lable_index = tf.strings.split(img_path, os.path.sep)[-1]           # 파일 이름 추출\n",
    "    lable_index = tf.strings.split(lable_index, '.')[0]                 # 확장자 제거\n",
    "    lable_index = tf.strings.to_number(lable_index, out_type=tf.int32)  # 숫자 변환\n",
    "\n",
    "    # 레이블 생성\n",
    "    lable_all = tf.gather(df_all, lable_index)                          # df 에서 lable_index 번째 label 추출\n",
    "\n",
    "    # 타겟과 레이블 반환\n",
    "    return (image, lable_all)\n",
    "\n",
    "@tf.function\n",
    "def add_noise(image, label):\n",
    "    # 이미지 잡음\n",
    "    #noise = tf.random.normal(shape=tf.shape(image), mean=0.5, stddev=0.2, dtype=tf.float32)     # 정규 분포\n",
    "    noise = tf.random.uniform(shape=tf.shape(image), minval=-0.7, maxval=0.7, dtype=tf.float32)  # 균등 분포\n",
    "    image = image + noise\n",
    "    image = tf.clip_by_value(image, 0.0, 1.0)\n",
    "    return image, label\n",
    "\n",
    "@tf.function\n",
    "def rotate_image(image, label):\n",
    "    # 이미지 회전\n",
    "    angle = tf.random.uniform([], minval=-15, maxval=15, dtype=tf.float32)\n",
    "    angle_rad = angle * (3.141592653589793 / 180.0)\n",
    "    image = tfa.image.rotate(image, angle_rad)\n",
    "    return image, label\n",
    "\n",
    "def scale_image(image, label):\n",
    "    # 이미지 확대 및 축소\n",
    "    pass\n",
    "\n",
    "def shift_image(image, label):\n",
    "    # 이미지 상하좌우로 이동\n",
    "    pass\n",
    "\n",
    "def shake_image(image, label):\n",
    "    # 이미지 흔들림\n",
    "    pass\n",
    "\n",
    "@tf.function\n",
    "def filter_dataset(image, label):\n",
    "    # label이 모두 0인 경우 필터링\n",
    "    return tf.math.reduce_any(label != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 확인해보기\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_images(dataset, num_images):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for images, labels in dataset.take(1):\n",
    "        for i in range(num_images):\n",
    "            ax = plt.subplot(4, 8, i + 1)\n",
    "            plt.imshow(images[i], cmap='gray')\n",
    "            plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 생성\n",
    "dataset = tf.data.Dataset.list_files(os.path.join(dataset_dir, '*.png'))\n",
    "\n",
    "# map : make_data\n",
    "dataset = dataset.map(make_data, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# map : shift_image\n",
    "#dataset = dataset.map(shift_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# map : rotate_image\n",
    "dataset = dataset.map(rotate_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# map : scale_image\n",
    "#dataset = dataset.map(scale_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# map : shake_image\n",
    "#dataset = dataset.map(shake_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# map : add_noise\n",
    "dataset = dataset.map(add_noise, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# filter\n",
    "dataset = dataset.filter(filter_dataset)\n",
    "\n",
    "# cache\n",
    "dataset = dataset.cache()\n",
    "\n",
    "# shuffle\n",
    "dataset = dataset.shuffle(buffer_size=25000)\n",
    "\n",
    "# repeat\n",
    "#dataset = dataset.repeat(3)\n",
    "\n",
    "# train, validation\n",
    "ds_validation = dataset.take(320).batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "ds_train = dataset.skip(320).batch(32)\n",
    "\n",
    "# 만들어진 데이터셋 확인\n",
    "#plot_images(ds_validation, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inception module\n",
    "def inception_module(x, filters):\n",
    "    # 1x1 conv\n",
    "    out1_1 = tf.keras.layers.Conv2D(filters[0], 1, strides=1, padding='same', activation='relu')(x)\n",
    "    # 1x1 conv -> 3x3 conv\n",
    "    out2_1 = tf.keras.layers.Conv2D(filters[1], 1, strides=1, padding='same', activation='relu')(x)\n",
    "    out2_2 = tf.keras.layers.Conv2D(filters[2], 3, strides=1, padding='same', activation='relu')(out2_1)\n",
    "    # 1x1 conv -> 5x5 conv\n",
    "    out3_1 = tf.keras.layers.Conv2D(filters[3], 1, strides=1, padding='same', activation='relu')(x)\n",
    "    out3_2 = tf.keras.layers.Conv2D(filters[4], 5, strides=1, padding='same', activation='relu')(out3_1)\n",
    "    # 3x3 max_pool -> 1x1 conv\n",
    "    out4_1 = tf.keras.layers.MaxPooling2D(pool_size=3, strides=1, padding='same')(x)\n",
    "    out4_2 = tf.keras.layers.Conv2D(filters[5], 1, strides=1, padding='same', activation='relu')(out4_1)\n",
    "\n",
    "    # out1_1 + out2_2 + out3_2 + out4_4\n",
    "    output = tf.keras.layers.Concatenate(axis=-1)([out1_1, out2_2, out3_2, out4_2])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GoogLeNet -> MyGoogLeNet\n",
    "def MyGoogLeNet(input_shape=(512, 192, 1), num_classes=12):\n",
    "    # 입력\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "    # 합성곱 1\n",
    "    x = tf.keras.layers.Conv2D(filters=64, kernel_size=7, strides=2, padding='same', activation='relu')(inputs)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    # 합성곱 2\n",
    "    x = tf.keras.layers.Conv2D(filters=64, kernel_size=1, strides=1, padding='same', activation='relu')(x)\n",
    "    x = tf.keras.layers.Conv2D(filters=192, kernel_size=3, strides=1, padding='same', activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    # 인셉션 모듈\n",
    "    x = inception_module(x, [64, 128, 96, 32, 16, 32])\n",
    "    x = inception_module(x, [128, 192, 128, 96, 32, 64])\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    x = inception_module(x, [192, 208, 96, 48, 16, 64])\n",
    "    x = inception_module(x, [160, 224, 112, 64, 24, 64])\n",
    "    x = inception_module(x, [128, 256, 128, 64, 24, 64])\n",
    "    x = inception_module(x, [112, 288, 144, 64, 32, 64])\n",
    "    x = inception_module(x, [256, 320, 160, 128, 32, 128])\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    x = inception_module(x, [256, 320, 160, 128, 32, 128])\n",
    "    x = inception_module(x, [384, 384, 192, 128, 48, 128])\n",
    "    # 전역 평균 풀링\n",
    "    x = tf.keras.layers.AveragePooling2D(pool_size=(16, 6))(x)\n",
    "    # 출력층\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dropout(0.4)(x)\n",
    "    output = tf.keras.layers.Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "    # 모델 생성\n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[output], name='MyGoogLeNet')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 초기화\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 모델 생성 및 학습\n",
    "with tf.device('/device:GPU:0'):\n",
    "    # 모델 생성\n",
    "    model = MyGoogLeNet()\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # 모델 학습\n",
    "    model.fit(ds_train, epochs=4, validation_data=ds_validation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_2.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
