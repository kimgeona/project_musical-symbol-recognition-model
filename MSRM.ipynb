{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 패키지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chorokmoo/_MyDev/_Anaconda/anaconda3/envs/new/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/Users/chorokmoo/_MyDev/_Anaconda/anaconda3/envs/new/lib/python3.10/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.12.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf             # 텐서플로\n",
    "import tensorflow_addons as tfa     # 텐서플로 애드온\n",
    "import pandas as pd                 # 판다스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU 사용 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용 가능한 모든 GPU 리스트\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "# 사용할 프로세서 선택 : GPU\n",
    "if gpus:\n",
    "    try: tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    except RuntimeError as e: print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터셋 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 주소\n",
    "dataset_dir = os.path.join('.', 'datasets', 'MusicalSymbol-v.1.1.5')\n",
    "\n",
    "# CSV 파일 주소\n",
    "csv_dir = os.path.join(dataset_dir, 'label.csv')\n",
    "\n",
    "# csv 파일 불러오기\n",
    "df = pd.read_csv(csv_dir)\n",
    "\n",
    "# name을 정수값으로 추출\n",
    "df['name_int'] = df['name'].str.extract('(\\d+)').astype(int)\n",
    "\n",
    "# 정수값을 기준으로 정렬 및 인덱스 초기화\n",
    "df = df.sort_values('name_int')\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# 필요 없는 name, name_int 열 제거\n",
    "df = df.drop(columns=['name', 'name_int'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_extract(dataframe, keywords):\n",
    "    # 빈 데이터 프레임 생성\n",
    "    new_df = pd.DataFrame()\n",
    "\n",
    "    # 기존 데이터 프레임 추출 시작\n",
    "    for key in keywords:\n",
    "        # 키워드 추출\n",
    "        name_list = [s for s in dataframe.columns.to_numpy() if key in s]\n",
    "        \n",
    "        # 추출된 키워드 열 끼리 병합\n",
    "        for n in name_list:\n",
    "            # 키워드 열 끼리 or 연산\n",
    "            if key in new_df:   new_df[key.strip()] = new_df[key] | dataframe[n]\n",
    "            else:               new_df[key.strip()] = dataframe[n]\n",
    "    \n",
    "    # 새로 생성된 데이터 프레임 반환\n",
    "    return new_df\n",
    "\n",
    "def column_pick(dataframe, keywords):\n",
    "    # 빈 데이터 프레임 생성\n",
    "    new_df = pd.DataFrame()\n",
    "\n",
    "    # 기존 데이터 프레임 추출 시작\n",
    "    for key in keywords:\n",
    "        # 키워드 추출\n",
    "        name_list = [s for s in dataframe.columns.to_numpy() if key in s]\n",
    "\n",
    "        # 추출된 키워드로 데이터 프레임 새로 만들기\n",
    "        for n in name_list:\n",
    "            new_df[n.strip()] = dataframe[n]\n",
    "    \n",
    "    # 새로 생성된 데이터 프레임 반환\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['note' 'accidental' 'articulation' 'dynamic' 'octave' 'ornament'\n",
      " 'repetition' 'clef' 'key' 'measure' 'rest' 'time']\n",
      "['staff-a4-0-0' 'staff-b4-0-0' 'staff-c5-0-0' 'staff-d4-0-0'\n",
      " 'staff-d5-0-0' 'staff-e4-0-0' 'staff-e5-0-0' 'staff-f4-0-0'\n",
      " 'staff-f5-0-0' 'staff-g4-0-0' 'staff-g5-0-0']\n",
      "['note-down-1' 'note-down-16' 'note-down-2' 'note-down-32' 'note-down-4'\n",
      " 'note-down-64' 'note-down-8' 'note-up-1' 'note-up-16' 'note-up-2'\n",
      " 'note-up-32' 'note-up-4' 'note-up-64' 'note-up-8']\n",
      "['accidental-flat' 'accidental-flat-double' 'accidental-natural'\n",
      " 'accidental-sharp' 'accidental-sharp-double']\n",
      "['articulation-accent' 'articulation-fermata-down'\n",
      " 'articulation-fermata-up' 'articulation-marcato-down'\n",
      " 'articulation-marcato-up' 'articulation-portato'\n",
      " 'articulation-staccatissimo' 'articulation-staccato'\n",
      " 'articulation-tenuto']\n",
      "['dynamic-crescendo' 'dynamic-crescendo-end' 'dynamic-crescendo-middle'\n",
      " 'dynamic-crescendo-start' 'dynamic-decrescendo' 'dynamic-decrescendo-end'\n",
      " 'dynamic-decrescendo-middle' 'dynamic-decrescendo-start' 'dynamic-forte'\n",
      " 'dynamic-fortepiano' 'dynamic-fortissimo' 'dynamic-fortississimo'\n",
      " 'dynamic-mezzo-forte' 'dynamic-mezzo-piano' 'dynamic-pianissimo'\n",
      " 'dynamic-pianississimo' 'dynamic-piano' 'dynamic-sforzando']\n",
      "['octave-down-end' 'octave-down-middle' 'octave-down-start-15'\n",
      " 'octave-down-start-8' 'octave-up-end' 'octave-up-middle'\n",
      " 'octave-up-start-15' 'octave-up-start-8']\n",
      "['ornament-mordent-lower' 'ornament-mordent-upper' 'ornament-tril'\n",
      " 'ornament-tril-plus' 'ornament-turn' 'ornament-turn-inverted'\n",
      " 'ornament-turn-slash']\n",
      "['repetition-coda' 'repetition-da-capo' 'repetition-dal-segno'\n",
      " 'repetition-segno' 'repetition-simile' 'repetition-simile-multi'\n",
      " 'repetition-slash' 'repetition-volta-end-close'\n",
      " 'repetition-volta-end-open' 'repetition-volta-middle'\n",
      " 'repetition-volta-start-1' 'repetition-volta-start-2']\n",
      "['clef-c-alto' 'clef-c-tenor' 'clef-f' 'clef-g' 'clef-g-double'\n",
      " 'clef-g-minus-15' 'clef-g-minus-8' 'clef-g-plus-15' 'clef-g-plus-8']\n",
      "['key-flat-1' 'key-flat-2' 'key-flat-3' 'key-flat-4' 'key-flat-5'\n",
      " 'key-flat-6' 'key-flat-7' 'key-sharp-1' 'key-sharp-2' 'key-sharp-3'\n",
      " 'key-sharp-4' 'key-sharp-5' 'key-sharp-6' 'key-sharp-7']\n",
      "['measure-bar' 'measure-bar-dotted' 'measure-bar-double'\n",
      " 'measure-bar-double-bold' 'measure-repeat-end' 'measure-repeat-start']\n",
      "['rest-1' 'rest-1-dot' 'rest-16' 'rest-16-dot' 'rest-2' 'rest-2-dot'\n",
      " 'rest-32' 'rest-32-dot' 'rest-4' 'rest-4-dot' 'rest-64' 'rest-64-dot'\n",
      " 'rest-8' 'rest-8-dot' 'rest-caesura']\n",
      "['time-common' 'time-cut']\n"
     ]
    }
   ],
   "source": [
    "# 악상 기호 전체 분류\n",
    "df_all = column_extract(df, keywords=[ \n",
    "    'note', \n",
    "    'accidental', \n",
    "    'articulation', \n",
    "    'dynamic', \n",
    "    'octave', \n",
    "    'ornament', \n",
    "    'repetition', \n",
    "    'clef', \n",
    "    'key', \n",
    "    'measure', \n",
    "    'rest', \n",
    "    'time'\n",
    "])\n",
    "#\n",
    "print(df_all.columns.to_numpy())\n",
    "\n",
    "# 악상 기호 세부 분류\n",
    "df_specific = [\n",
    "    column_pick(df, keywords=['staff-']).drop(columns=['staff-half-left', 'staff-half-right']),\n",
    "    column_pick(df, keywords=['note']),\n",
    "    column_pick(df, keywords=['accidental']),\n",
    "    column_pick(df, keywords=['articulation']),\n",
    "    column_pick(df, keywords=['dynamic']),\n",
    "    column_pick(df, keywords=['octave']),\n",
    "    column_pick(df, keywords=['ornament']),\n",
    "    column_pick(df, keywords=['repetition']),\n",
    "    column_pick(df, keywords=['clef']),\n",
    "    column_pick(df, keywords=['key']),\n",
    "    column_pick(df, keywords=['measure']),\n",
    "    column_pick(df, keywords=['rest']),\n",
    "    column_pick(df, keywords=['time']),\n",
    "]\n",
    "#\n",
    "for df in df_specific: print(df.columns.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pandas 데이터 프레임을 tensorflow 텐서로 변환\n",
    "tdf_all         = tf.convert_to_tensor(df_all.values, dtype=tf.int16)\n",
    "tdf_specific    = [tf.convert_to_tensor(df.values, dtype=tf.int16) for df in df_specific ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 분류\n",
      "--------------------------------\n",
      "df_all          : (22617, 12) \n",
      "\n",
      "세부 분류\n",
      "--------------------------------\n",
      "df_pitch        : (22617, 11)\n",
      "df_note         : (22617, 14)\n",
      "df_accidental   : (22617, 5)\n",
      "df_articulation : (22617, 9)\n",
      "df_dynamic      : (22617, 18)\n",
      "df_octave       : (22617, 8)\n",
      "df_ornament     : (22617, 7)\n",
      "df_repetition   : (22617, 12)\n",
      "df_clef         : (22617, 9)\n",
      "df_key          : (22617, 14)\n",
      "df_measure      : (22617, 6)\n",
      "df_rest         : (22617, 15)\n",
      "df_time         : (22617, 2)\n"
     ]
    }
   ],
   "source": [
    "# shape 출력\n",
    "print('전체 분류')\n",
    "print('--------------------------------')\n",
    "print('df_all          :', tdf_all.shape, '\\n')\n",
    "\n",
    "print('세부 분류')\n",
    "print('--------------------------------')\n",
    "print('df_pitch        :', tdf_specific[0].shape)\n",
    "print('df_note         :', tdf_specific[1].shape)\n",
    "print('df_accidental   :', tdf_specific[2].shape)\n",
    "print('df_articulation :', tdf_specific[3].shape)\n",
    "print('df_dynamic      :', tdf_specific[4].shape)\n",
    "print('df_octave       :', tdf_specific[5].shape)\n",
    "print('df_ornament     :', tdf_specific[6].shape)\n",
    "print('df_repetition   :', tdf_specific[7].shape)\n",
    "print('df_clef         :', tdf_specific[8].shape)\n",
    "print('df_key          :', tdf_specific[9].shape)\n",
    "print('df_measure      :', tdf_specific[10].shape)\n",
    "print('df_rest         :', tdf_specific[11].shape)\n",
    "print('df_time         :', tdf_specific[12].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def make_data(img_path):\n",
    "    # 타겟 생성\n",
    "    image = tf.io.read_file(img_path)               # 파일 로드\n",
    "    image = tf.image.decode_png(image, channels=1)  # png 파일로 변환\n",
    "    image = tf.cast(image, tf.float32)              # uint8 -> float32\n",
    "    image = image / 255.0                           # 0~1 로 정규화\n",
    "    image = 1.0 - image                             # 흑백 이미지 반전\n",
    "\n",
    "    # 파일 이름에서 인덱스 얻기\n",
    "    lable_index = tf.strings.split(img_path, os.path.sep)[-1]           # 파일 이름 추출\n",
    "    lable_index = tf.strings.split(lable_index, '.')[0]                 # 확장자 제거\n",
    "    lable_index = tf.strings.to_number(lable_index, out_type=tf.int32)  # 숫자 변환\n",
    "\n",
    "    # 레이블 생성\n",
    "    lable_all = tf.gather(tdf_all, lable_index)                          # df 에서 lable_index 번째 label 추출\n",
    "    lable_specific = [tf.gather(tdf, lable_index) for tdf in tdf_specific]\n",
    "\n",
    "    # 타겟과 레이블 반환\n",
    "    return (image, (lable_all, *lable_specific))\n",
    "\n",
    "@tf.function\n",
    "def add_noise(image, label):\n",
    "    # 이미지 잡음\n",
    "    #noise = tf.random.normal(shape=tf.shape(image), mean=0.5, stddev=0.2, dtype=tf.float32)     # 정규 분포\n",
    "    noise = tf.random.uniform(shape=tf.shape(image), minval=-0.7, maxval=0.7, dtype=tf.float32)  # 균등 분포\n",
    "    image = image + noise\n",
    "    image = tf.clip_by_value(image, 0.0, 1.0)\n",
    "    return image, label\n",
    "\n",
    "@tf.function\n",
    "def rotate_image(image, label):\n",
    "    # 이미지 회전\n",
    "    angle = tf.random.uniform([], minval=-15, maxval=15, dtype=tf.float32)\n",
    "    angle_rad = angle * (3.141592653589793 / 180.0)\n",
    "    image = tfa.image.rotate(image, angle_rad)\n",
    "    return image, label\n",
    "\n",
    "def scale_image(image, label):\n",
    "    # 이미지 확대 및 축소\n",
    "    pass\n",
    "\n",
    "def shift_image(image, label):\n",
    "    # 이미지 상하좌우로 이동\n",
    "    pass\n",
    "\n",
    "def shake_image(image, label):\n",
    "    # 이미지 흔들림\n",
    "    pass\n",
    "\n",
    "@tf.function\n",
    "def filter_dataset(image, label):\n",
    "    # label이 모두 0인 경우 필터링\n",
    "    return tf.math.reduce_any(label != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 확인해보기\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_images(dataset, num_images):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for images, labels in dataset.take(1):\n",
    "        for i in range(num_images):\n",
    "            ax = plt.subplot(4, 8, i + 1)\n",
    "            plt.imshow(images[i], cmap='gray')\n",
    "            print(i, ' : ', [name for name, mask in zip(df_all.columns.to_numpy(), tf.gather(labels[0], i).numpy()) if mask==1])\n",
    "            plt.title(i)\n",
    "            plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 생성\n",
    "dataset = tf.data.Dataset.list_files(os.path.join(dataset_dir, '*.png'))\n",
    "\n",
    "# map : make_data\n",
    "dataset = dataset.map(make_data, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# map : shift_image\n",
    "#dataset = dataset.map(shift_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# map : rotate_image\n",
    "dataset = dataset.map(rotate_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# map : scale_image\n",
    "#dataset = dataset.map(scale_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# map : shake_image\n",
    "#dataset = dataset.map(shake_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# map : add_noise\n",
    "dataset = dataset.map(add_noise, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# filter\n",
    "#dataset = dataset.filter(filter_dataset)\n",
    "\n",
    "# cache\n",
    "dataset = dataset.cache()\n",
    "\n",
    "# shuffle\n",
    "dataset = dataset.shuffle(buffer_size=25000)\n",
    "\n",
    "# repeat\n",
    "#dataset = dataset.repeat(3)\n",
    "\n",
    "# train, validation\n",
    "ds_validation = dataset.take(320).batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "ds_train = dataset.skip(320).batch(32)\n",
    "\n",
    "# 만들어진 데이터셋 확인\n",
    "#plot_images(ds_validation, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inception module\n",
    "def inception_module(x, filters):\n",
    "    # 1x1 conv\n",
    "    out1_1 = tf.keras.layers.Conv2D(filters[0], 1, strides=1, padding='same', activation='relu')(x)\n",
    "    # 1x1 conv -> 3x3 conv\n",
    "    out2_1 = tf.keras.layers.Conv2D(filters[1], 1, strides=1, padding='same', activation='relu')(x)\n",
    "    out2_2 = tf.keras.layers.Conv2D(filters[2], 3, strides=1, padding='same', activation='relu')(out2_1)\n",
    "    # 1x1 conv -> 5x5 conv\n",
    "    out3_1 = tf.keras.layers.Conv2D(filters[3], 1, strides=1, padding='same', activation='relu')(x)\n",
    "    out3_2 = tf.keras.layers.Conv2D(filters[4], 5, strides=1, padding='same', activation='relu')(out3_1)\n",
    "    # 3x3 max_pool -> 1x1 conv\n",
    "    out4_1 = tf.keras.layers.MaxPooling2D(pool_size=3, strides=1, padding='same')(x)\n",
    "    out4_2 = tf.keras.layers.Conv2D(filters[5], 1, strides=1, padding='same', activation='relu')(out4_1)\n",
    "\n",
    "    # out1_1 + out2_2 + out3_2 + out4_4\n",
    "    output = tf.keras.layers.Concatenate(axis=-1)([out1_1, out2_2, out3_2, out4_2])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GoogLeNet -> MyGoogLeNet\n",
    "def MyGoogLeNet(input_shape=(512, 192, 1), num_classes=12):\n",
    "    # 입력\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "    # 합성곱 1\n",
    "    x = tf.keras.layers.Conv2D(filters=32, kernel_size=7, strides=2, padding='same', activation='relu')(inputs)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    # 합성곱 2\n",
    "    x = tf.keras.layers.Conv2D(filters=64, kernel_size=1, strides=1, padding='same', activation='relu')(x)\n",
    "    x = tf.keras.layers.Conv2D(filters=192, kernel_size=3, strides=1, padding='same', activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    # 인셉션 모듈\n",
    "    x = inception_module(x, [64, 128, 96, 32, 16, 32])\n",
    "    x = inception_module(x, [128, 192, 128, 96, 32, 64])\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    x = inception_module(x, [192, 208, 96, 48, 16, 64])\n",
    "    x = inception_module(x, [160, 224, 112, 64, 24, 64])\n",
    "    x = inception_module(x, [128, 256, 128, 64, 24, 64])\n",
    "    x = inception_module(x, [112, 288, 144, 64, 32, 64])\n",
    "    x = inception_module(x, [256, 320, 160, 128, 32, 128])\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    x = inception_module(x, [256, 320, 160, 128, 32, 128])\n",
    "    x = inception_module(x, [384, 384, 192, 128, 48, 128])\n",
    "    # 전역 평균 풀링\n",
    "    x = tf.keras.layers.AveragePooling2D(pool_size=(16, 6))(x)\n",
    "    # 출력층\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dropout(0.4)(x)\n",
    "    output = tf.keras.layers.Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "    # 모델 생성\n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[output], name='MyGoogLeNet')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RecognitionNet\n",
    "\n",
    "def layer_category(inputs, n):\n",
    "    layer = tf.keras.layers.Conv2D(filters=32, kernel_size=7, strides=1, padding='same', activation='relu')(inputs)\n",
    "    layer = tf.keras.layers.MaxPooling2D(pool_size=(2,2))(layer)\n",
    "    layer = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu')(layer)\n",
    "    layer = tf.keras.layers.MaxPooling2D(pool_size=(2,2))(layer)\n",
    "    layer = tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=1, padding='same', activation='relu')(layer)\n",
    "    layer = tf.keras.layers.MaxPooling2D(pool_size=(2,2))(layer)\n",
    "    layer = tf.keras.layers.Flatten()(layer)\n",
    "    layer = tf.keras.layers.Dense(256, activation='relu')(layer)\n",
    "    layer = tf.keras.layers.Dense(128, activation='relu')(layer)\n",
    "    layer_out = tf.keras.layers.Dense(n, activation='sigmoid')(layer)\n",
    "    return layer_out\n",
    "\n",
    "def layer_specific(inputs, n, pre_outputs=None, i=None):\n",
    "    # 이미지 인식 층\n",
    "    layer = tf.keras.layers.Conv2D(filters=32, kernel_size=7, strides=1, padding='same', activation='relu')(inputs)\n",
    "    layer = tf.keras.layers.MaxPooling2D(pool_size=(2,2))(layer)\n",
    "    layer = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu')(layer)\n",
    "    layer = tf.keras.layers.MaxPooling2D(pool_size=(2,2))(layer)\n",
    "    layer = tf.keras.layers.Flatten()(layer)\n",
    "    layer = tf.keras.layers.Dense(256, activation='relu')(layer)\n",
    "    layer = tf.keras.layers.Dense(128, activation='relu')(layer)\n",
    "    # 마스크 처리 층\n",
    "    if (pre_outputs is not None) and (i is not None):\n",
    "        mask = tf.gather(pre_outputs, i)\n",
    "        mask = tf.keras.layers.Reshape((1,))(mask)\n",
    "        layer = tf.keras.layers.Multiply()([layer, mask])\n",
    "    # 출력층\n",
    "    layer_out = tf.keras.layers.Dense(n, activation='softmax')(layer)\n",
    "    return layer_out\n",
    "\n",
    "def MusicalSymbolRecognitionModel():\n",
    "    # 입력 \n",
    "    inputs = tf.keras.layers.Input(shape=(192, 512, 1))\n",
    "\n",
    "    # 전체 분류 층\n",
    "    layer_categorical = layer_category(inputs, tdf_all.shape[-1])\n",
    "    \n",
    "    # 세부 분류 층\n",
    "    layer_pitch         = layer_specific(inputs, tdf_specific[0].shape[-1])\n",
    "    layer_note          = layer_specific(inputs, tdf_specific[1].shape[-1], layer_categorical, 0)\n",
    "    layer_accidental    = layer_specific(inputs, tdf_specific[2].shape[-1], layer_categorical, 1)\n",
    "    layer_articulation  = layer_specific(inputs, tdf_specific[3].shape[-1], layer_categorical, 2)\n",
    "    layer_dynamic       = layer_specific(inputs, tdf_specific[4].shape[-1], layer_categorical, 3)\n",
    "    layer_octave        = layer_specific(inputs, tdf_specific[5].shape[-1], layer_categorical, 4)\n",
    "    layer_ornament      = layer_specific(inputs, tdf_specific[6].shape[-1], layer_categorical, 5)\n",
    "    layer_repetition    = layer_specific(inputs, tdf_specific[7].shape[-1], layer_categorical, 6)\n",
    "    layer_clef          = layer_specific(inputs, tdf_specific[8].shape[-1], layer_categorical, 7)\n",
    "    layer_key           = layer_specific(inputs, tdf_specific[9].shape[-1], layer_categorical, 8)\n",
    "    layer_measure       = layer_specific(inputs, tdf_specific[10].shape[-1], layer_categorical, 9)\n",
    "    layer_rest          = layer_specific(inputs, tdf_specific[11].shape[-1], layer_categorical, 10)\n",
    "    layer_time          = layer_specific(inputs, tdf_specific[12].shape[-1], layer_categorical, 11)\n",
    "\n",
    "    # 모델 생성\n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[\n",
    "        layer_categorical,\n",
    "        layer_pitch,\n",
    "        layer_note,\n",
    "        layer_accidental,\n",
    "        layer_articulation,\n",
    "        layer_dynamic,\n",
    "        layer_octave,\n",
    "        layer_ornament,\n",
    "        layer_repetition,\n",
    "        layer_clef,\n",
    "        layer_key,\n",
    "        layer_measure,\n",
    "        layer_rest,\n",
    "        layer_time\n",
    "    ], name='MusicalSymbolRecognitionModel')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 초기화\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 모델 생성 및 학습\n",
    "with tf.device('/device:GPU:0'):\n",
    "    # 모델 생성\n",
    "    model = MusicalSymbolRecognitionModel()\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=[\n",
    "            'binary_crossentropy',\n",
    "            'categorical_crossentropy',\n",
    "            'categorical_crossentropy',\n",
    "            'categorical_crossentropy',\n",
    "            'categorical_crossentropy',\n",
    "            'categorical_crossentropy',\n",
    "            'categorical_crossentropy',\n",
    "            'categorical_crossentropy',\n",
    "            'categorical_crossentropy',\n",
    "            'categorical_crossentropy',\n",
    "            'categorical_crossentropy',\n",
    "            'categorical_crossentropy',\n",
    "            'categorical_crossentropy',\n",
    "            'categorical_crossentropy'\n",
    "        ],\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # 모델 학습\n",
    "    history = model.fit(ds_train, epochs=10, validation_data=ds_validation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_2.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
